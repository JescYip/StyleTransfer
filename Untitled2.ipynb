{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrW7zs6ZgNmQ94PJNe+i1C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JescYip/StyleTransfer/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!bash init_style_transfer_v2.sh\n",
        "!pip uninstall -y tensorboard tensorflow jax jaxlib\n",
        "!pip install tensorboardX\n",
        "!pip install lpips\n",
        "%cd /content/StyleTransfer"
      ],
      "metadata": {
        "id": "-csLuWz8jrhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --config configs/llff_own.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --expname own"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UgWL_pTyElj",
        "outputId": "0d6e8dd0-1a4e-4013-aa43-4960af5e6b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own.txt', expname='own', basedir='./log1', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='./data/WikiArt', progress_refresh_rate=10, with_depth=False, downsample_train=2.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=10000, dataset_name='own_data', patch_size=256, chunk_size=4096, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0001, L1_weight_rest=4e-05, Ortho_weight=0.0, TV_weight_density=1.0, TV_weight_app=1.0, TV_weight_feature=0.0, style_weight=0, content_weight=0, image_tv_weight=0, featuremap_tv_weight=0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=0, fea_pe=0, featureC=128, ckpt=None, render_only=0, render_test=1, render_train=0, render_path=1, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=1000000.0, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097152, N_voxel_final=262144000, upsamp_list=[2000, 3000, 4000, 5500], update_AlphaMask_list=[2500], idx_view=0, N_vis=-1, vis_every=10000)\n",
            "Loading data train (40): 100% 40/40 [00:01<00:00, 39.20it/s]\n",
            "Loading data test (40): 100% 40/40 [00:00<00:00, 61.90it/s]\n",
            "aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [128, 128, 128]\n",
            "sampling step size:  tensor(0.0118, device='cuda:0')\n",
            "sampling number:  440\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "lr decay 0.1 10000\n",
            "initial Ortho_reg_weight 0.0\n",
            "initial L1_reg_weight 0.0001\n",
            "initial TV_weight density: 1.0 appearance: 1.0\n",
            "Iteration 02000: train_psnr = 7.88 test_psnr = 0.00 mse = 0.165502:  20% 2000/10000 [00:45<03:04, 43.48it/s]aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [191, 191, 191]\n",
            "sampling step size:  tensor(0.0079, device='cuda:0')\n",
            "sampling number:  659\n",
            "upsamping to [191, 191, 191]\n",
            "reset lr to initial\n",
            "Iteration 02500: train_psnr = 7.90 test_psnr = 0.00 mse = 0.158589:  25% 2500/10000 [00:59<03:29, 35.87it/s]/usr/local/lib/python3.11/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "bbox: (tensor([-1.5000, -1.5000, -1.2789], device='cuda:0'), tensor([1.5000, 1.5000, 1.5000], device='cuda:0')) alpha rest %77.616539\n",
            "AlphaMask max: 1.0\n",
            "AlphaMask min: 0.0\n",
            "====> shrinking ...\n",
            "aabb tensor([-1.5000, -1.5000, -1.2789,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size (tensor(191, device='cuda:0'), tensor(191, device='cuda:0'), tensor(177, device='cuda:0'))\n",
            "sampling step size:  tensor(0.0079, device='cuda:0')\n",
            "sampling number:  643\n",
            "continuing L1_reg_weight 4e-05\n",
            "Iteration 03000: train_psnr = 7.93 test_psnr = 0.00 mse = 0.159990:  30% 3000/10000 [01:14<03:09, 36.95it/s]aabb tensor([-1.5000, -1.5000, -1.2789,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [293, 293, 271]\n",
            "sampling step size:  tensor(0.0051, device='cuda:0')\n",
            "sampling number:  987\n",
            "upsamping to [293, 293, 271]\n",
            "reset lr to initial\n",
            "Iteration 04000: train_psnr = 7.97 test_psnr = 0.00 mse = 0.160711:  40% 4000/10000 [01:59<04:43, 21.16it/s]aabb tensor([-1.5000, -1.5000, -1.2789,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [439, 439, 406]\n",
            "sampling step size:  tensor(0.0034, device='cuda:0')\n",
            "sampling number:  1481\n",
            "upsamping to [439, 439, 406]\n",
            "reset lr to initial\n",
            "Iteration 05500: train_psnr = 8.06 test_psnr = 0.00 mse = 0.157957:  55% 5500/10000 [03:53<05:36, 13.36it/s]aabb tensor([-1.5000, -1.5000, -1.2789,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [656, 656, 608]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2215\n",
            "upsamping to [656, 656, 608]\n",
            "reset lr to initial\n",
            "40it [00:20,  1.97it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "Iteration 09990: train_psnr = 8.13 test_psnr = 0.00 mse = 0.147270: 100% 10000/10000 [14:28<00:00, 11.51it/s]\n",
            "0it [00:00, ?it/s]init_lpips: lpips_alex\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "init_lpips: lpips_vgg\n",
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n",
            "40it [00:31,  1.27it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "======> own test all psnr: 8.16736821280621 <========================\n",
            "========> torch.Size([40, 4, 4])\n",
            "40it [00:12,  3.26it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --config configs/llff_own.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --expname own"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3dISgmHjsa3",
        "outputId": "d207398a-430a-4785-caf0-ade3f0a3dd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own.txt', expname='own', basedir='./log1', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='./data/WikiArt', progress_refresh_rate=10, with_depth=False, downsample_train=2.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=10000, dataset_name='own_data', patch_size=256, chunk_size=4096, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0, L1_weight_rest=0, Ortho_weight=0.0, TV_weight_density=1.0, TV_weight_app=1.0, TV_weight_feature=0.0, style_weight=0, content_weight=0, image_tv_weight=0, featuremap_tv_weight=0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=0, fea_pe=0, featureC=128, ckpt=None, render_only=0, render_test=1, render_train=0, render_path=1, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=1000000.0, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097156, N_voxel_final=262144000, upsamp_list=[2000, 3000, 4000, 5500], update_AlphaMask_list=[2500], idx_view=0, N_vis=-1, vis_every=10000)\n",
            "Loading data train (40): 100% 40/40 [00:03<00:00, 12.93it/s]\n",
            "Loading data test (40): 100% 40/40 [00:01<00:00, 25.83it/s]\n",
            "aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [128, 128, 128]\n",
            "sampling step size:  tensor(0.0118, device='cuda:0')\n",
            "sampling number:  440\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "lr decay 0.1 10000\n",
            "initial Ortho_reg_weight 0.0\n",
            "initial L1_reg_weight 0.0\n",
            "initial TV_weight density: 1.0 appearance: 1.0\n",
            "Iteration 02000: train_psnr = 7.87 test_psnr = 0.00 mse = 0.165488:  20% 2000/10000 [00:42<02:41, 49.61it/s]aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [191, 191, 191]\n",
            "sampling step size:  tensor(0.0079, device='cuda:0')\n",
            "sampling number:  659\n",
            "upsamping to [191, 191, 191]\n",
            "reset lr to initial\n",
            "Iteration 02500: train_psnr = 7.90 test_psnr = 0.00 mse = 0.158664:  25% 2500/10000 [00:55<03:15, 38.38it/s]/usr/local/lib/python3.11/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "bbox: (tensor([-1.5000, -1.5000, -1.5000], device='cuda:0'), tensor([1.5000, 1.5000, 1.5000], device='cuda:0')) alpha rest %83.131310\n",
            "====> shrinking ...\n",
            "aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size (tensor(191, device='cuda:0'), tensor(191, device='cuda:0'), tensor(191, device='cuda:0'))\n",
            "sampling step size:  tensor(0.0079, device='cuda:0')\n",
            "sampling number:  659\n",
            "continuing L1_reg_weight 0\n",
            "Iteration 03000: train_psnr = 7.93 test_psnr = 0.00 mse = 0.159902:  30% 3000/10000 [01:09<02:54, 40.19it/s]aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [286, 286, 286]\n",
            "sampling step size:  tensor(0.0053, device='cuda:0')\n",
            "sampling number:  988\n",
            "upsamping to [286, 286, 286]\n",
            "reset lr to initial\n",
            "Iteration 04000: train_psnr = 7.97 test_psnr = 0.00 mse = 0.160644:  40% 4000/10000 [01:52<04:07, 24.21it/s]aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [427, 427, 427]\n",
            "sampling step size:  tensor(0.0035, device='cuda:0')\n",
            "sampling number:  1476\n",
            "upsamping to [427, 427, 427]\n",
            "reset lr to initial\n",
            "Iteration 05500: train_psnr = 8.06 test_psnr = 0.00 mse = 0.158092:  55% 5500/10000 [03:39<05:19, 14.08it/s]aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [640, 640, 640]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2214\n",
            "upsamping to [640, 640, 640]\n",
            "reset lr to initial\n",
            "40it [00:19,  2.01it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "Iteration 09990: train_psnr = 8.14 test_psnr = 0.00 mse = 0.147025: 100% 10000/10000 [13:46<00:00, 12.10it/s]\n",
            "0it [00:00, ?it/s]init_lpips: lpips_alex\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "init_lpips: lpips_vgg\n",
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n",
            "40it [00:31,  1.28it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "======> own test all psnr: 8.167790697694803 <========================\n",
            "========> torch.Size([40, 4, 4])\n",
            "40it [00:12,  3.22it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --config configs/llff_own.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --expname own"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T7ZlUEZ2dWv",
        "outputId": "58aefc3b-8d92-4872-ff09-2de2d280263c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own.txt', expname='own', basedir='./log1', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='./data/WikiArt', progress_refresh_rate=10, with_depth=False, downsample_train=2.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=30000, dataset_name='own_data', patch_size=256, chunk_size=4096, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0001, L1_weight_rest=4e-05, Ortho_weight=0.0, TV_weight_density=1.0, TV_weight_app=1.0, TV_weight_feature=0.0, style_weight=0, content_weight=0, image_tv_weight=0, featuremap_tv_weight=0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=0, fea_pe=0, featureC=128, ckpt=None, render_only=0, render_test=1, render_train=0, render_path=1, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=1000000.0, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097152, N_voxel_final=262144000, upsamp_list=[2000, 3000, 4000, 5500], update_AlphaMask_list=[2500], idx_view=0, N_vis=-1, vis_every=10000)\n",
            "Loading data train (40): 100% 40/40 [00:00<00:00, 54.68it/s]\n",
            "Loading data test (40): 100% 40/40 [00:00<00:00, 63.53it/s]\n",
            "aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [128, 128, 128]\n",
            "sampling step size:  tensor(0.0118, device='cuda:0')\n",
            "sampling number:  440\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "lr decay 0.1 30000\n",
            "initial Ortho_reg_weight 0.0\n",
            "initial L1_reg_weight 0.0001\n",
            "initial TV_weight density: 1.0 appearance: 1.0\n",
            "Iteration 02000: train_psnr = 7.86 test_psnr = 0.00 mse = 0.165694:   7% 2000/30000 [00:46<10:12, 45.73it/s]aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [191, 191, 191]\n",
            "sampling step size:  tensor(0.0079, device='cuda:0')\n",
            "sampling number:  659\n",
            "upsamping to [191, 191, 191]\n",
            "reset lr to initial\n",
            "Iteration 02500: train_psnr = 7.90 test_psnr = 0.00 mse = 0.158825:   8% 2500/30000 [01:01<12:30, 36.65it/s]/usr/local/lib/python3.11/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "bbox: (tensor([-1.5000, -1.5000, -1.1526], device='cuda:0'), tensor([1.5000, 1.5000, 1.5000], device='cuda:0')) alpha rest %73.511841\n",
            "====> shrinking ...\n",
            "aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size (tensor(191, device='cuda:0'), tensor(191, device='cuda:0'), tensor(169, device='cuda:0'))\n",
            "sampling step size:  tensor(0.0079, device='cuda:0')\n",
            "sampling number:  634\n",
            "continuing L1_reg_weight 4e-05\n",
            "Iteration 03000: train_psnr = 7.94 test_psnr = 0.00 mse = 0.159853:  10% 3000/30000 [01:16<11:44, 38.30it/s]aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [298, 298, 263]\n",
            "sampling step size:  tensor(0.0051, device='cuda:0')\n",
            "sampling number:  990\n",
            "upsamping to [298, 298, 263]\n",
            "reset lr to initial\n",
            "Iteration 04000: train_psnr = 7.98 test_psnr = 0.00 mse = 0.160835:  13% 4000/30000 [02:01<19:14, 22.52it/s]aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [445, 445, 394]\n",
            "sampling step size:  tensor(0.0034, device='cuda:0')\n",
            "sampling number:  1482\n",
            "upsamping to [445, 445, 394]\n",
            "reset lr to initial\n",
            "Iteration 05500: train_psnr = 8.06 test_psnr = 0.00 mse = 0.158088:  18% 5500/30000 [03:54<30:36, 13.34it/s]aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [666, 666, 589]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2219\n",
            "upsamping to [666, 666, 589]\n",
            "reset lr to initial\n",
            "40it [00:19,  2.01it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "40it [00:19,  2.01it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "40it [00:20,  1.98it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "Iteration 29990: train_psnr = 8.19 test_psnr = 8.20 mse = 0.148451: 100% 30000/30000 [1:00:48<00:00,  8.22it/s]\n",
            "0it [00:00, ?it/s]init_lpips: lpips_alex\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "init_lpips: lpips_vgg\n",
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n",
            "40it [00:31,  1.26it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "======> own test all psnr: 8.222933830275785 <========================\n",
            "========> torch.Size([40, 4, 4])\n",
            "40it [00:12,  3.23it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_feature.py \\\n",
        "  --config configs/llff_own_feature.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --expname own_feature \\\n",
        "  --ckpt /content/StyleTransfer/log1/own/own.th\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FIrZfirkl1hK",
        "outputId": "feaaa484-0689-4d66-e8c3-357d61c2430c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own_feature.txt', expname='own_feature', basedir='./log1_feature', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='./data/WikiArt', progress_refresh_rate=10, with_depth=False, downsample_train=4.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=10000, dataset_name='own_data', patch_size=256, chunk_size=4096, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0, L1_weight_rest=0, Ortho_weight=0.0, TV_weight_density=0.0, TV_weight_app=0.0, TV_weight_feature=80.0, style_weight=0, content_weight=0, image_tv_weight=0, featuremap_tv_weight=0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=6, fea_pe=6, featureC=128, ckpt='/content/StyleTransfer/log1/own/own.th', render_only=0, render_test=0, render_train=0, render_path=0, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=1000000.0, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097156, N_voxel_final=262144000, upsamp_list=[2000, 3000, 4000, 5500], update_AlphaMask_list=[2500], idx_view=0, N_vis=5, vis_every=10000)\n",
            "Loading data train (40): 100% 40/40 [00:00<00:00, 56.11it/s]\n",
            "[WARNING] patch_size 256 太大，自动 fallback 为 min(H,W) = 125\n",
            "aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [666, 666, 589]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2219\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "====> prepare_feature_data (low memory + save per frame)...\n",
            "  0% 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100% 40/40 [00:07<00:00,  5.06it/s]\n",
            "====> Feature extraction DONE. Total features: torch.Size([1000000, 256])\n",
            "lr decay 0.1 10000\n",
            "initial TV_weight_feature: 80.0\n",
            "Iteration 09990: psnr = 11.59: 100% 10000/10000 [44:15<00:00,  3.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_style.py \\\n",
        "  --config configs/llff_own_style.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --wikiartdir /content/drive/MyDrive/data/WikiArt/images \\\n",
        "  --expname own_style \\\n",
        "  --ckpt /content/StyleTransfer/log1_feature/own_feature/own_feature.th"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkzcbjEC4zEE",
        "outputId": "e88ffd37-5317-441c-ac93-8459ccac4999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own_style.txt', expname='own_style', basedir='./log1_style', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='/content/drive/MyDrive/data/WikiArt/images', progress_refresh_rate=10, with_depth=False, downsample_train=4.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=10000, dataset_name='own_data', patch_size=64, chunk_size=2048, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0, L1_weight_rest=0, Ortho_weight=0.0, TV_weight_density=0.0, TV_weight_app=0.0, TV_weight_feature=0.0, style_weight=20.0, content_weight=1.0, image_tv_weight=0.0, featuremap_tv_weight=0.0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=6, fea_pe=6, featureC=128, ckpt='/content/StyleTransfer/log1_feature/own_feature/own_feature.th', render_only=0, render_test=0, render_train=0, render_path=0, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=300, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097156, N_voxel_final=262144000, upsamp_list=None, update_AlphaMask_list=None, idx_view=0, N_vis=5, vis_every=10000)\n",
            "Loading data train (40): 100% 40/40 [00:00<00:00, 87.55it/s]\n",
            "aabb tensor([-1.5000, -1.5000, -1.5000,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [640, 640, 640]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2214\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "lr decay 0.1 10000\n",
            "100% 10000/10000 [37:26<00:00,  4.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_style.py \\\n",
        "  --config configs/llff_own_style.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --wikiartdir /content/drive/MyDrive/data/WikiArt/images \\\n",
        "  --expname own_style \\\n",
        "  --ckpt /content/StyleTransfer/log1_feature/own_feature/own_feature.th"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7jqa95cYPbs",
        "outputId": "96b5f0d2-da75-46da-9014-3a9ba50a0e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own_style.txt', expname='own_style', basedir='./log1_style', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='/content/drive/MyDrive/data/WikiArt/images', progress_refresh_rate=10, with_depth=False, downsample_train=4.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=10000, dataset_name='own_data', patch_size=124, chunk_size=2048, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0, L1_weight_rest=0, Ortho_weight=0.0, TV_weight_density=0.0, TV_weight_app=0.0, TV_weight_feature=0.0, style_weight=20.0, content_weight=1.0, image_tv_weight=0.0, featuremap_tv_weight=0.0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=6, fea_pe=6, featureC=128, ckpt='/content/StyleTransfer/log1_feature/own_feature/own_feature.th', render_only=0, render_test=0, render_train=0, render_path=0, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=300, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097156, N_voxel_final=262144000, upsamp_list=None, update_AlphaMask_list=None, idx_view=0, N_vis=5, vis_every=10000)\n",
            "Loading data train (40): 100% 40/40 [00:00<00:00, 81.89it/s]\n",
            "aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [666, 666, 589]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2219\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "lr decay 0.1 10000\n",
            "100% 10000/10000 [43:06<00:00,  3.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --config /content/StyleTransfer/configs/llff_own.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --ckpt /content/StyleTransfer/log1/own/own.th \\\n",
        "  --render_only 1 \\\n",
        "  --render_test 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McFynyAf-CDf",
        "outputId": "e4522c1b-9f18-4bfc-d792-b2290a9e3f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='/content/StyleTransfer/configs/llff_own.txt', expname='own_style', basedir='./log1', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='./data/WikiArt', progress_refresh_rate=10, with_depth=False, downsample_train=2.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=30000, dataset_name='own_data', patch_size=256, chunk_size=4096, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0001, L1_weight_rest=4e-05, Ortho_weight=0.0, TV_weight_density=1.0, TV_weight_app=1.0, TV_weight_feature=0.0, style_weight=0, content_weight=0, image_tv_weight=0, featuremap_tv_weight=0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=0, fea_pe=0, featureC=128, ckpt='/content/StyleTransfer/log1/own/own.th', render_only=1, render_test=1, render_train=0, render_path=1, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=1000000.0, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097152, N_voxel_final=262144000, upsamp_list=[2000, 3000, 4000, 5500], update_AlphaMask_list=[2500], idx_view=0, N_vis=-1, vis_every=10000)\n",
            "Loading data test (40): 100% 40/40 [00:00<00:00, 42.08it/s]\n",
            "aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [666, 666, 589]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2219\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "0it [00:00, ?it/s]init_lpips: lpips_alex\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "init_lpips: lpips_vgg\n",
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n",
            "40it [00:31,  1.26it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "40it [00:12,  3.22it/s]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 400) to (256, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_feature.py \\\n",
        "  --config configs/llff_own_feature.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --expname own_feature \\\n",
        "  --ckpt /content/StyleTransfer/log1_feature/own_feature/own_feature.th \\\n",
        "  --render_only 1 \\\n",
        "  --render_test 1 \\\n",
        "  --render_path 0 \\\n",
        "  --chunk_size 1024\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAJP7JG0h8tf",
        "outputId": "9ba32bc9-5756-416d-95d2-1183cb6492b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own_feature.txt', expname='own_feature', basedir='./log1_feature', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='./data/WikiArt', progress_refresh_rate=10, with_depth=False, downsample_train=4.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=10000, dataset_name='own_data', patch_size=256, chunk_size=1024, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0, L1_weight_rest=0, Ortho_weight=0.0, TV_weight_density=0.0, TV_weight_app=0.0, TV_weight_feature=80.0, style_weight=0, content_weight=0, image_tv_weight=0, featuremap_tv_weight=0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=6, fea_pe=6, featureC=128, ckpt='/content/StyleTransfer/log1_feature/own_feature/own_feature.th', render_only=1, render_test=1, render_train=0, render_path=0, export_mesh=0, style_img=None, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=1000000.0, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097156, N_voxel_final=262144000, upsamp_list=[2000, 3000, 4000, 5500], update_AlphaMask_list=[2500], idx_view=0, N_vis=5, vis_every=10000)\n",
            "Loading data test (40): 100% 40/40 [00:00<00:00, 82.89it/s]\n",
            "aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [666, 666, 589]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2219\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "40it [00:40,  1.02s/it]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (125, 200) to (128, 208) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (125, 200) to (128, 208) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_style.py \\\n",
        "  --config configs/llff_own_style.txt \\\n",
        "  --datadir /content/drive/MyDrive/data/nerf_data \\\n",
        "  --expname own_style \\\n",
        "  --ckpt /content/StyleTransfer/log1_style/own_style/own_style.th\\\n",
        "  --render_only 1 \\\n",
        "  --render_train 0 \\\n",
        "  --render_test 1 \\\n",
        "  --render_path 1 \\\n",
        "  --chunk_size 1024 \\\n",
        "  --rm_weight_mask_thre 0.0001 \\\n",
        "  --style_img /content/drive/MyDrive/data/WikiArt/images/landscape/00246e71f367b009f0aa7d0127b2bb08c.jpg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGEcOZif-FQ8",
        "outputId": "c77673dd-2009-4430-e0e4-9f888b8fc74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(config='configs/llff_own_style.txt', expname='own_style', basedir='./log1_style', add_timestamp=0, datadir='/content/drive/MyDrive/data/nerf_data', wikiartdir='./data/WikiArt', progress_refresh_rate=10, with_depth=False, downsample_train=4.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=10000, dataset_name='own_data', patch_size=124, chunk_size=1024, lr_init=0.02, lr_basis=0.0001, lr_finetune=1e-05, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0, L1_weight_rest=0, Ortho_weight=0.0, TV_weight_density=0.0, TV_weight_app=0.0, TV_weight_feature=0.0, style_weight=20.0, content_weight=1.0, image_tv_weight=0.0, featuremap_tv_weight=0.0, n_lamb_sigma=[16, 4, 4], n_lamb_sh=[48, 12, 12], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_Fea', pos_pe=6, view_pe=6, fea_pe=6, featureC=128, ckpt='/content/StyleTransfer/log1_style/own_style/own_style.th', render_only=1, render_test=1, render_train=0, render_path=1, export_mesh=0, style_img='/content/drive/MyDrive/data/WikiArt/images/landscape/00246e71f367b009f0aa7d0127b2bb08c.jpg', lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='relu', ndc_ray=1, nSamples=300, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097156, N_voxel_final=262144000, upsamp_list=None, update_AlphaMask_list=None, idx_view=0, N_vis=5, vis_every=10000)\n",
            "aabb tensor([-1.5000, -1.5000, -1.1526,  1.5000,  1.5000,  1.5000], device='cuda:0')\n",
            "grid size [666, 666, 589]\n",
            "sampling step size:  tensor(0.0023, device='cuda:0')\n",
            "sampling number:  2219\n",
            "pos_pe 6 view_pe 0 fea_pe 0\n",
            "Loading data train (40): 100% 40/40 [00:00<00:00, 51.00it/s]\n",
            "40it [04:43,  7.10s/it]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (500, 800) to (512, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (500, 800) to (512, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "Loading data train (40): 100% 40/40 [00:00<00:00, 43.99it/s]\n",
            "40it [02:59,  4.48s/it]\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (500, 800) to (512, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (500, 800) to (512, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ]
    }
  ]
}